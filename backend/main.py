from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from bs4 import BeautifulSoup
import googlemaps
import requests
import os
from dotenv import load_dotenv

load_dotenv()
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰OpenAI APIã‚­ãƒ¼ã‚’å–å¾—
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
CHAT_MODEL = os.getenv("CHAT_MODEL")
SERPER_API_KEY = os.getenv("SERPER_API_KEY")

llm = ChatOpenAI(
    openai_api_key=OPENAI_API_KEY,
    temperature=0,
    model=CHAT_MODEL,
)

GOOGLE_MAPS_API_KEY = os.getenv("GOOGLE_MAPS_API_KEY")

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # æœ¬ç•ªã§ã¯é™å®šã—ãŸæ–¹ãŒå®‰å…¨ï¼ˆä»Šã¯ * ã§OKï¼‰
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class Location(BaseModel):
    latitude: float
    longitude: float

# Google Maps APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
gmaps = googlemaps.Client(key=GOOGLE_MAPS_API_KEY)

@app.get("/")
def read_root():
    return {"message": "Hello World"}

# å£ã‚³ãƒŸã‚‚å–å¾—ã™ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³
@app.post("/search")
def search_jongso(location: Location):
    places_result = gmaps.places_nearby(
        location=(location.latitude, location.longitude),
        radius=3000,
        keyword="éº»é›€",
        type="establishment",
        language="ja"
    )

    results = []
    for place in places_result.get("results", []):
        name = place.get("name", "")
        address = place.get("vicinity", "")
        rating = place.get("rating", 0)
        user_ratings_total = place.get("user_ratings_total", 0)
        place_id = place.get("place_id", "")

        # å£ã‚³ãƒŸå–å¾—
        details = gmaps.place(
            place_id=place_id,
            language="ja"
        )
        reviews = details.get("result", {}).get("reviews", [])
        review_texts = [r.get("text", "") for r in reviews]

        # â˜… ã“ã“ã§LangChainä½¿ã£ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¼æ„Ÿæƒ…åˆ†æ
        summary = ""
        positive_score = None
        negative_score = None

        if review_texts:
            combined_reviews = "\n".join(review_texts[:5])  # æœ€åˆã®5ãƒ¬ãƒ“ãƒ¥ãƒ¼ã ã‘ä½¿ã†
            prompt = ChatPromptTemplate.from_template("""
ã‚ãªãŸã¯{genre}ã®å°‚é–€å®¶ã§ã™ã€‚

ä»¥ä¸‹ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’èª­ã¿ã€ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å³å¯†ã«å¾“ã£ã¦è¦ç´„ã¨ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚’ã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
è¦ç´„: ï¼ˆè¦ç´„æ–‡ï¼‰
ãƒã‚¸ãƒ†ã‚£ãƒ–åº¦: ï¼ˆåŠè§’æ•°å­—ã®ã¿ã€%ã¯ã¤ã‘ã‚‹ï¼‰
ãƒã‚¬ãƒ†ã‚£ãƒ–åº¦: ï¼ˆåŠè§’æ•°å­—ã®ã¿ã€%ã¯ã¤ã‘ã‚‹ï¼‰

ãƒ¬ãƒ“ãƒ¥ãƒ¼:
{reviews}
""")
            chain = prompt | llm
            try:
                response = chain.invoke({
                    "genre": "é›€è˜",
                    "style": "è¦ªã—ã¿ã‚„ã™ãã€ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã«ã¾ã¨ã‚ã‚‹",
                    "reviews": combined_reviews,
                })
                # â˜…ã“ã“ã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹ï¼
                lines = response.content.splitlines()
                for line in lines:
                    if "è¦ç´„" in line:
                        summary = line.split("è¦ç´„:")[-1].strip()
                    if "ãƒã‚¸ãƒ†ã‚£ãƒ–åº¦" in line:
                        positive_score = int(line.split("ãƒã‚¸ãƒ†ã‚£ãƒ–åº¦:")[-1].replace("%", "").strip())
                    if "ãƒã‚¬ãƒ†ã‚£ãƒ–åº¦" in line:
                        negative_score = int(line.split("ãƒã‚¬ãƒ†ã‚£ãƒ–åº¦:")[-1].replace("%", "").strip())

                print("lines", lines)

            except Exception as e:
                print(f"Sentiment analysis error: {e}")

        # ğŸ”¥ ç¦ç…™æƒ…å ±å–å¾—ã™ã‚‹ï¼
        urls = search_google_places(f"{name} {address} é›€è˜ ç¦ç…™")
        texts = []
        for url in urls:
            page_text = fetch_page_text(url)
            if page_text:
                texts.append(page_text)

        combined_text = "\n".join(texts)
        if combined_text:
            smoking_chain = smoking_check_prompt | llm
            try:
                response = smoking_chain.invoke({"text": combined_text})
                smoking_judgement = response.content.strip()
            except Exception as e:
                print(f"ç¦ç…™åˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")

        location = place.get("geometry", {}).get("location", {})
        lat = location.get("lat")
        lng = location.get("lng")

        results.append({
            "name": name,
            "address": address,
            "rating": rating,
            "user_ratings_total": user_ratings_total,
            "lat": lat,
            "lng": lng,
            "summary": summary,
            "positive_score": positive_score,
            "negative_score": negative_score,
            "smoking": smoking_judgement,
        })

    results.sort(
        key=lambda x: (-calculate_adjusted_rating(x), -x["user_ratings_total"])
    )

    return {
        "results": results
    }

def calculate_adjusted_rating(place):
    base_rating = place["rating"]
    positive_score = place.get("positive_score")

    if positive_score is not None:
        return base_rating + (positive_score / 100)  # ãƒã‚¸ãƒ†ã‚£ãƒ–åº¦ã‚’å°‘ã—åŠ ç®—
    else:
        return base_rating


def search_google_places(query):
    url = "https://google.serper.dev/search"

    payload = {
        "q": query,
        "gl": "jp",  # æ—¥æœ¬å„ªå…ˆ
        "hl": "ja"   # æ—¥æœ¬èªå„ªå…ˆ
    }

    headers = {
        "X-API-KEY": SERPER_API_KEY,
        "Content-Type": "application/json"
    }

    response = requests.post(url, headers=headers, json=payload)

    if response.status_code == 200:
        data = response.json()
        # ä¸Šä½3ä»¶ãã‚‰ã„ã®URLã ã‘å–ã‚‹ä¾‹
        urls = [item.get('link') for item in data.get('organic', [])[:3]]
        return urls
    else:
        print(f"Serperæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {response.text}")
        return []

def fetch_page_text(url):
    try:
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            # ä½™è¨ˆãªJSã‚„åºƒå‘Šã¯çœã„ã¦ã€æœ¬æ–‡ã ã‘æŠ½å‡º
            return soup.get_text(separator="\n", strip=True)
        else:
            print(f"ãƒšãƒ¼ã‚¸å–å¾—ã‚¨ãƒ©ãƒ¼: {url}")
            return ""
    except Exception as e:
        print(f"ã‚¯ãƒ­ãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼: {url}, {e}")
        return ""

def analyze_smoking_info(page_text):
    prompt = ChatPromptTemplate.from_template("""
ä»¥ä¸‹ã®ãƒšãƒ¼ã‚¸å†…å®¹ã‚’èª­ã¿ã€ã“ã®æ–½è¨­ãŒã€Œç¦ç…™ã€ã€Œåˆ†ç…™ã€ã€Œå–«ç…™å¯ã€ã®ã©ã‚Œã«è©²å½“ã™ã‚‹ã‹ã‚’å¿…ãš1èªã§ç­”ãˆã¦ãã ã•ã„ã€‚
ã‚‚ã—æƒ…å ±ãŒæ˜ç¢ºã«è¨˜è¼‰ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€ã€Œæƒ…å ±ãªã—ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚
ã¾ãŸã€ãã®åˆ¤å®šã®æ ¹æ‹ ã‚‚ç°¡å˜ã«1æ–‡ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
ç¦ç…™çŠ¶æ³: ï¼ˆç¦ç…™ or åˆ†ç…™ or å–«ç…™å¯ or æƒ…å ±ãªã—ï¼‰
æ ¹æ‹ : ï¼ˆæœ¬æ–‡ã‹ã‚‰è¦ç‚¹ã‚’1æ–‡ã§ï¼‰

ãƒšãƒ¼ã‚¸å†…å®¹:
{page_text}
""")

    chain = prompt | llm

    try:
        response = chain.invoke({
            "page_text": page_text,
        })
        lines = response.content.splitlines()
        smoking_status = None
        reason = ""

        for line in lines:
            if "ç¦ç…™çŠ¶æ³" in line:
                smoking_status = line.split("ç¦ç…™çŠ¶æ³:")[-1].strip()
            if "æ ¹æ‹ " in line:
                reason = line.split("æ ¹æ‹ :")[-1].strip()

        return smoking_status, reason

    except Exception as e:
        print(f"ç¦ç…™åˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
        return None, ""

# ç¦ç…™åˆ¤å®šç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
smoking_check_prompt = ChatPromptTemplate.from_template("""
æ¬¡ã®æ–‡ç« ã‚’èª­ã‚“ã§ã€ã“ã®é›€è˜ã®å–«ç…™çŠ¶æ³ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›å½¢å¼ã€‘ï¼ˆå¿…ãšã“ã®4ã¤ã‹ã‚‰é¸ã‚“ã§ãã ã•ã„ï¼‰
- ç¦ç…™
- åˆ†ç…™
- å–«ç…™å¯
- æƒ…å ±ãªã—

æ–‡ç« :
{text}
""")
